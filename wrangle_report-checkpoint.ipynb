{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: Wragle_report on WeRateDogs Data Analysis Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### The Project on the WeRateDogs twitter account fully integrates the fundamentals of Exploratory Data Analysis with more empphasis on data wrangling, the Project aims to analyse social engagements among dog lovers. The dataset was analysed following adequate wrangling operations through which we have been able to explore the concepts of data wrangling. The exercise began with gathering three datasets from different sources, this process reinforces the importance of data wrangling using a variety of python libraries. The first dataset we explored is twitter-archive-enhanced.csv file manually uploaded to our virtual environment. The second dataset which is the image-prediction.tsv, was programmatically downloaded using python requests library. The third dataset will require the use of Tweepy to query Twitter's API upon approval, unfortunately this approval could not be secured within the desired time frame, but an alternative json file contining previously queried data was provided, this json file will be read line by line into a dataframe. Each dataset contains different obsevations needed for our analysis and will need to be combined to create a master dataset. This concept is similar to the database concept of referential integrity through primary and foreign keys, but before that can be done the data will need to be assesed and cleaned. \n",
    "   \n",
    "   ### Visual and programmatic assessment was carried out to detect defects in all three datasets, giving us an idea of what quality and tidiness issues needed to be addressed. a wide range of issues were detected ranging from missing data, inconsistent data, structural deficiency and many more but the main focus is to document atleast 8 quality issues and 2 tidiness issues some of which are:\n",
    " 1.twitter archive data contains retweets. we are focusing on original tweets only.\n",
    "\n",
    "2.the dog name column contains words that are inconsistent with the majority of the names in the column.\n",
    "\n",
    "3.Some columns are not necessary for my analysis\n",
    "\n",
    "4.rating denominator column contains inconsistent data and incorrect data\n",
    "\n",
    "4.rating numerator column contains inconsistent values. e.t.c\n",
    "  ### After document these issues, the next step is to address them, this the final stage of the wrangling exercise, copies of each dataset were created for reference purposes. This stage of the wrangling process was the most challenging  it necessitated several iterations and hours of studing concepts that were previously unfamiliar. At the cleaning stage, I made use of the Define-Code-Test framework to provide some structure to the  process and made sure to go back and forth on this exercise till my dataset was beaten into a cleaner frame. Upon completion of the data cleaning exercise, it became abundantly clear just how important data wrangling is to Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
